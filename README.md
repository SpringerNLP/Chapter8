# Chapter 8: Automatic Speech Recognition
In this case study we explore two frameworks for speech recognition: CMU Sphinx and Kaldi.
Given varying dependencies, we split them into two separate Docker images and handel them separately. 
Both methods leverage the [Common Voice](https://voice.mozilla.org/en/datasets) and contain their own README for instructions. 

The [CMUSphinx](https://cmusphinx.github.io/) case study trains a speech recognition model using GMM/HMM models. 
The [Kaldi](http://kaldi-asr.org/) case study follows the [common voice recipe](https://github.com/kaldi-asr/kaldi/tree/master/egs/commonvoice/s5), scripted in a jupyter notebook for closer inspection. 

## [Sphinx Case Study](Sphinx) 

## [Kaldi Case Study](Kaldi) 


## Book Reference
More information can be found at: [Deep Learning for NLP and Speech Recognition](https://www.amazon.com/Deep-Learning-NLP-Speech-Recognition/dp/3030145956) by [Springer](https://www.springer.com/us/book/9783030145958) 
