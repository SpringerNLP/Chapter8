{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaldi Training\n",
    "Because Kaldi relies heavily on shell scripting and CLI commands, many of the commands that follow leverage the Kaldi scripts. \n",
    "This notebook should be running inside the Kaldi docker image in order for these commands to run. \n",
    "\n",
    "This leverages the Kaldi recipe from https://github.com/kaldi-asr/kaldi/tree/master/egs/commonvoice/s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check that we are running in the docker container. \n",
    "assert os.path.exists(\"/kaldi/egs/commonvoice/s5/run.sh\"), \\\n",
    "       \"Common Voice script does not exist. Are you sure \" + \\\n",
    "       \"you are running this notebook in the docker container?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd /kaldi/tools && ./install_srilm.sh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "Set the data directories and command variables. The command variables are useful if more resources are available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env data=/data/datasets/cv_corpus_v1\n",
    "%env data_url=https://common-voice-data-download.s3.amazonaws.com/cv_corpus_v1.tar.gz\n",
    "\n",
    "%env train_cmd=\"run.pl --mem 8G\"\n",
    "%env decode_cmd=\"run.pl --mem 8G\"\n",
    "%env mkgraph_cmd=\"run.pl --mem 8G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaldi/egs/commonvoice/s5/\n",
    "\n",
    ". ./cmd.sh\n",
    ". ./path.sh\n",
    "\n",
    "stage=0\n",
    "\n",
    ". ./utils/parse_options.sh\n",
    "\n",
    "set -euo pipefail\n",
    "\n",
    "if [ $stage -le 0 ]; then\n",
    "  mkdir -p $data\n",
    "\n",
    "  local/download_and_untar.sh $(dirname $data) $data_url\n",
    "fi\n",
    "echo $data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data, LM, and vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaldi/egs/commonvoice/s5/\n",
    "\n",
    "for part in valid-train valid-dev valid-test; do\n",
    "  # use underscore-separated names in data directories.\n",
    "  local/data_prep.pl $data cv-$part data/$(echo $part | tr - _)\n",
    "done\n",
    "\n",
    "# Prepare ARPA LM and vocabulary using SRILM\n",
    "local/prepare_lm.sh data/valid_train\n",
    "# Prepare the lexicon and various phone lists\n",
    "# Pronunciations for OOV words are obtained using a pre-trained Sequitur model\n",
    "local/prepare_dict.sh\n",
    "\n",
    "# Prepare data/lang and data/local/lang directories\n",
    "utils/prepare_lang.sh data/local/dict \\\n",
    "  '<unk>' data/local/lang data/lang || exit 1\n",
    "\n",
    "utils/format_lm.sh data/lang data/local/lm.gz data/local/dict/lexicon.txt data/lang_test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract MFCC features:\n",
    "\n",
    "The dataset is reasonably large, so this can take a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaldi/egs/commonvoice/s5/\n",
    "\n",
    "mfccdir=mfcc\n",
    "# # spread the mfccs over various machines, as this data-set is quite large.\n",
    "# if [[  $(hostname -f) ==  *.clsp.jhu.edu ]]; then\n",
    "#     mfcc=$(basename mfccdir) # in case was absolute pathname (unlikely), get basename.\n",
    "#     utils/create_split_dir.pl /export/b{07,14,16,17}/$USER/kaldi-data/mfcc/commonvoice/s5/$mfcc/storage \\\n",
    "#       $mfccdir/storage\n",
    "# fi\n",
    "\n",
    "for part in valid_train valid_dev valid_test; do\n",
    "    steps/make_mfcc.sh --cmd \"$train_cmd\" --nj 20 data/$part exp/make_mfcc/$part $mfccdir\n",
    "    steps/compute_cmvn_stats.sh data/$part exp/make_mfcc/$part $mfccdir\n",
    "done\n",
    "\n",
    "# Get the shortest 10000 utterances first because those are more likely\n",
    "# to have accurate alignments.\n",
    "utils/subset_data_dir.sh --shortest data/valid_train 10000 data/train_10kshort || exit 1;\n",
    "utils/subset_data_dir.sh data/valid_train 20000 data/train_20k || exit 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the monophone system (HMM-GMM model):\n",
    "1. Kaldi takes a data directory and language directory, and it stores the outputs in the experiment directory. \n",
    "2. The utils/mkgraph.sh combines the HMM with the lexicon and grammar to create the decoding graph with an FST. \n",
    "3. The test set is transcribed using the decoding graph created. \n",
    "4. The model is used to create an alignment of the transcript phone states to the audio. \n",
    "\n",
    "Results in a model that gives a WER of 52.06 on the Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /kaldi/egs/commonvoice/s5/\n",
    "\n",
    "steps/train_mono.sh --boost-silence 1.25 --nj 20 --cmd \"run.pl --mem 8G\" \\\n",
    "  data/train_10kshort data/lang exp/mono || exit 1;\n",
    "(\n",
    "  utils/mkgraph.sh data/lang_test exp/mono exp/mono/graph\n",
    "  for testset in valid_dev; do\n",
    "    steps/decode.sh --nj 20 --cmd \"run.pl --mem 8G\" exp/mono/graph \\\n",
    "    data/$testset exp/mono/decode_$testset\n",
    "  done\n",
    ")&\n",
    "steps/align_si.sh --boost-silence 1.25 --nj 10 --cmd \"run.pl --mem 8G\" \\\n",
    "  data/train_20k data/lang exp/mono exp/mono_ali_train_20k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train delta and double delta triphone system\n",
    "Using the alignments from the monophone model, a delta and double delta triphone system is trained.\n",
    "\n",
    "Resulting model gives a WER of 25.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaldi/egs/commonvoice/s5/\n",
    "\n",
    "steps/train_deltas.sh --boost-silence 1.25 --cmd \"$train_cmd\" \\\n",
    "  2000 10000 data/train_20k data/lang exp/mono_ali_train_20k exp/tri1\n",
    "\n",
    "# decode using the tri1 model\n",
    "(\n",
    "  utils/mkgraph.sh data/lang_test exp/tri1 exp/tri1/graph\n",
    "  for testset in valid_dev; do\n",
    "    steps/decode.sh --nj 20 --cmd \"$decode_cmd\" exp/tri1/graph \\\n",
    "      data/$testset exp/tri1/decode_$testset\n",
    "  done\n",
    ")&\n",
    "\n",
    "steps/align_si.sh --nj 10 --cmd \"$train_cmd\" \\\n",
    "  data/train_20k data/lang exp/tri1 exp/tri1_ali_train_20k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an LDA+MLLT system to compute better alignments for the input of the NN.\n",
    "\n",
    "Resulting model gives a WER of 21.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaldi/egs/commonvoice/s5/\n",
    "\n",
    "steps/train_lda_mllt.sh --cmd \"$train_cmd\" \\\n",
    "  --splice-opts \"--left-context=3 --right-context=3\" 2500 15000 \\\n",
    "  data/train_20k data/lang exp/tri1_ali_train_20k exp/tri2b\n",
    "\n",
    "# decode using the LDA+MLLT model\n",
    "utils/mkgraph.sh data/lang_test exp/tri2b exp/tri2b/graph\n",
    "(\n",
    "  for testset in valid_dev; do\n",
    "    steps/decode.sh --nj 20 --cmd \"$decode_cmd\" exp/tri2b/graph \\\n",
    "      data/$testset exp/tri2b/decode_$testset\n",
    "  done\n",
    ")&\n",
    "\n",
    "# Align utts using the tri2b model\n",
    "steps/align_si.sh --nj 10 --cmd \"$train_cmd\" --use-graphs true \\\n",
    "  data/train_20k data/lang exp/tri2b exp/tri2b_ali_train_20k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train tri3b, which is LDA+MLLT+SAT\n",
    "\n",
    "Resulting model give a WER of 22.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaldi/egs/commonvoice/s5/\n",
    "\n",
    "steps/train_sat.sh --cmd \"$train_cmd\" 2500 15000 \\\n",
    "  data/train_20k data/lang exp/tri2b_ali_train_20k exp/tri3b\n",
    "\n",
    "# decode using the tri3b model\n",
    "(\n",
    "  utils/mkgraph.sh data/lang_test exp/tri3b exp/tri3b/graph\n",
    "  for testset in valid_dev; do\n",
    "    steps/decode_fmllr.sh --nj 10 --cmd \"$decode_cmd\" \\\n",
    "      exp/tri3b/graph data/$testset exp/tri3b/decode_$testset\n",
    "  done\n",
    ")&"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train another LDA+MLLT+SAT model on the new alignments. \n",
    "\n",
    "Resulting model gives a WER of 17.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaldi/egs/commonvoice/s5/\n",
    "\n",
    "# Align utts in the full training set using the tri3b model\n",
    "steps/align_fmllr.sh --nj 20 --cmd \"$train_cmd\" \\\n",
    "  data/valid_train data/lang \\\n",
    "  exp/tri3b exp/tri3b_ali_valid_train\n",
    "\n",
    "# train another LDA+MLLT+SAT system on the entire training set\n",
    "steps/train_sat.sh  --cmd \"$train_cmd\" 4200 40000 \\\n",
    "  data/valid_train data/lang \\\n",
    "  exp/tri3b_ali_valid_train exp/tri4b\n",
    "\n",
    "# decode using the tri4b model\n",
    "(\n",
    "  utils/mkgraph.sh data/lang_test exp/tri4b exp/tri4b/graph\n",
    "  for testset in valid_dev; do\n",
    "    steps/decode_fmllr.sh --nj 20 --cmd \"$decode_cmd\" \\\n",
    "      exp/tri4b/graph data/$testset \\\n",
    "      exp/tri4b/decode_$testset\n",
    "  done\n",
    ")&"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a chain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaldi/egs/commonvoice/s5/\n",
    "\n",
    "local/chain/run_tdnn.sh --stage 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
